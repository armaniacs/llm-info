# 要求定義書: LLMゲートウェイ情報可視化CLIツール (名称: `llm-info`)

## 1. 目的

OpenAI互換のLLMサービス（APIゲートウェイ）が提供しているモデル一覧や、各モデルの制約事項（`max_tokens`等）を、開発者がターミナル上から素早く把握できるようにする。

## 2. ターゲット

* 複数のLLMをゲートウェイ経由で利用するエンジニア。
* 利用可能なモデル名やトークン上限を、コードを書く前に確認したいユーザー。

## 3. 機能要件

### 3.1 モデル情報取得機能

* **LiteLLM互換モード**: `/model/info` エンドポイントにリクエストを送り、詳細なメタデータ（`max_tokens`, `input_cost`, `mode`等）を取得する。
* **標準互換モード**: `/v1/models` エンドポイントから、提供されているモデルのID一覧を取得する。
* **自動フォールバック**: `/model/info` が利用不可の場合、自動的に `/v1/models` へ切り替えて情報を取得する。

### 3.2 可視化機能

* **テーブル表示**: 取得した情報を整理し、ターミナル上で読みやすい表形式で出力する。
* **動的な列制御**: `/model/info` から取得できた情報量に応じて、表示する列（トークン上限やコスト等）を動的に変更する。

### 3.3 CLI操作設定

* **接続先設定**: ベースURLやAPIキーを引数、または環境変数から指定可能にする。
* **タイムアウト管理**: 応答がないサーバーに対して無限に待機しないよう、適切なタイムアウト処理を行う。

### 3.4 設定ファイル

`~/.config/llm-info/llm-info.yaml ` とする。
GATEWAY_URL と API_KEY を、ターゲットごとに設定できるようにする。

## 4. 非機能要件

* **可搬性**: Go言語で実装し、OSに依存しないシングルバイナリとして配布可能にする。
* **ユーザビリティ**: プログラミング初心者でも理解しやすいシンプルなエラーメッセージを表示する。

## 5. 画面設計（出力イメージ）

```text
+----------------------+------------+--------+-------------+
|      MODEL NAME      | MAX TOKENS |  MODE  | INPUT COST  |
+----------------------+------------+--------+-------------+
| gpt-4                |       8192 | chat   |     0.00003 |
| claude-3-opus        |     200000 | chat   |     0.000015|
| gemini-1.5-pro       |    1000000 | chat   |           0 |
+----------------------+------------+--------+-------------+

```

## 6. 技術スタック（案）

* **言語**: Go (1.21以上)
* **主なライブラリ**:
* `net/http`: API通信
* `encoding/json`: JSONパース
* `github.com/olekukonko/tablewriter`: テーブル表示
* `github.com/spf13/cobra` (将来的な拡張用): CLIコマンド管理



