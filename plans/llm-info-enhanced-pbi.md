# プロダクトバックログアイテム: LLMゲートウェイ情報可視化CLIツール 機能拡張版

## プロダクトバックログアイテム群

### PBI 1: 標準互換モードと自動フォールバック機能

**タイトル**: OpenAI標準互換モードの追加と自動フォールバック機能

**ユーザーストーリー**:
開発者として、LiteLLM互換でないゲートウェイにも対応したい、なぜなら利用可能なLLMサービスの幅を広げたいから

**ビジネス価値**:
- 互換性向上：より多くのLLMゲートウェイに対応
- ユーザー体験：自動フォールバックにより手動設定が不要
- 柔軟性：様々なゲートウェイ環境で利用可能

**BDD受け入れシナリオ**:
```gherkin
Scenario: OpenAI標準互換ゲートウェイからモデル情報を取得する
  Given OpenAI標準互換ゲートウェイのURLが指定されている
  When ユーザーがllm-infoコマンドを実行する
  Then /v1/modelsエンドポイントからモデル一覧が取得される
  And モデル名のみがテーブル表示される

Scenario: LiteLLM互換モードが利用不可の場合に自動フォールバックする
  Given LiteLLM互換ゲートウェイのURLが指定されている
  And /model/infoエンドポイントが利用不可
  When ユーザーがllm-infoコマンドを実行する
  Then 自動的に/v1/modelsエンドポイントにフォールバックする
  And ユーザーにはフォールバックしたことが通知される
```

**受け入れ基準**:
- [ ] OpenAI標準の`/v1/models`エンドポイントに対応
- [ ] `/model/info`失敗時に自動的に`/v1/models`へフォールバック
- [ ] フォールバック時にユーザーに通知
- [ ] 両モードでのエラーハンドリング

**t_wadaスタイル テスト戦略**:
```
E2Eテスト:
- 標準互換ゲートウェイでのテスト
- フォールバックシナリオのテスト

統合テスト:
- 両エンドポイントの切り替えロジック
- レスポンス形式の正規化処理

単体テスト:
- フォールバック判定ロジック
- 各エンドポイントのレスポンス処理
```

**見積もり**: 3ストーリーポイント

---

### PBI 2: 設定ファイル機能

**タイトル**: 設定ファイルによるゲートウェイ管理機能

**ユーザーストーリー**:
開発者として、よく使うゲートウェイ情報を設定ファイルに保存したい、なぜなら毎回コマンドライン引数を入力する手間を省きたいから

**ビジネス価値**:
- 利便性向上：頻繁使用するゲートウェイの簡単な切り替え
- 生産性向上：コマンド入力の削減
- チーム標準化：設定ファイルの共有による環境統一

**BDD受け入れシナリオ**:
```gherkin
Scenario: 設定ファイルからゲートウェイ情報を読み込む
  Given ~/.config/llm-info/llm-info.yamlにゲートウェイ情報が設定されている
  When ユーザーがllm-infoコマンドを引数なしで実行する
  Then 設定ファイルからデフォルトゲートウェイ情報が読み込まれる
  And そのゲートウェイのモデル情報が表示される

Scenario: 複数のゲートウェイを切り替えて使用する
  Given 設定ファイルに複数のゲートウェイが登録されている
  When ユーザーが--gatewayオプションでゲートウェイ名を指定する
  Then 指定されたゲートウェイの情報が使用される
```

**受け入れ基準**:
- [ ] `~/.config/llm-info/llm-info.yaml`から設定を読み込み
- [ ] 複数ゲートウェイの登録と切り替え
- [ ] コマンドライン引数による設定の上書き
- [ ] 設定ファイルの作成ヘルプ機能

**t_wadaスタイル テスト戦略**:
```
E2Eテスト:
- 設定ファイルを使用したコマンド実行テスト
- 複数ゲートウェイ切り替えテスト

統合テスト:
- 設定ファイルパーサーと設定マネージャーの連携
- コマンドライン引数と設定ファイルの優先順位

単体テスト:
- YAMLファイルのパース処理
- 設定値のバリデーション
- デフォルト値処理
```

**見積もり**: 3ストーリーポイント

---

### PBI 3: 環境変数サポート

**タイトル**: 環境変数による設定機能

**ユーザーストーリー**:
開発者として、環境変数でゲートウェイ情報を設定したい、なぜならCI/CDパイプラインやコンテナ環境で利用したいから

**ビジネス価値**:
- 環境対応：CI/CDやコンテナ環境での利用
- セキュリティ：APIキーを環境変数で管理
- 柔軟性：設定方法の選択肢拡大

**BDD受け入れシナリオ**:
```gherkin
Scenario: 環境変数からゲートウェイ情報を読み込む
  Given LLM_INFO_URLとLLM_INFO_API_KEY環境変数が設定されている
  When ユーザーがllm-infoコマンドを実行する
  Then 環境変数からゲートウェイ情報が読み込まれる
  And そのゲートウェイのモデル情報が表示される

Scenario: 設定の優先順位が正しく動作する
  Given 設定ファイルと環境変数の両方に設定がある
  And コマンドライン引数も指定されている
  When ユーザーがllm-infoコマンドを実行する
  Then コマンドライン引数 > 環境変数 > 設定ファイルの優先順位で設定が使用される
```

**受け入れ基準**:
- [ ] `LLM_INFO_URL`と`LLM_INFO_API_KEY`環境変数に対応
- [ ] 設定の優先順位：コマンドライン > 環境変数 > 設定ファイル
- [ ] 環境変数のバリデーション

**t_wadaスタイル テスト戦略**:
```
統合テスト:
- 設定ソース間の優先順位テスト
- 環境変数パーサーのテスト

単体テスト:
- 環境変数の読み込み処理
- 優先順位判定ロジック
```

**見積もり**: 2ストーリーポイント

---

### PBI 4: 高度な表示機能

**タイトル**: モデル情報の高度な表示とフィルタリング機能

**ユーザーストーリー**:
開発者として、特定の条件でモデル情報をフィルタリングしたい、なぜなら目的に合ったモデルを素早く見つけたいから

**ビジネス価値**:
- 検索性向上：目的のモデルの迅速な発見
- 比較機能：モデルの特性比較
- カスタマイズ：ユーザー要件に合わせた表示

**BDD受け入れシナリオ**:
```gherkin
Scenario: モデル名でフィルタリングする
  Given 複数のモデルが利用可能なゲートウェイに接続している
  When ユーザーが--filter "gpt"オプションを指定して実行する
  Then モデル名に"gpt"を含むモデルのみが表示される

Scenario: トークン数でソートする
  Given 複数のモデルが利用可能なゲートウェイに接続している
  When ユーザーが--sort "max_tokens"オプションを指定して実行する
  Then 最大トークン数の昇順にモデルが表示される

Scenario: JSON形式で出力する
  Given スクリプトからllm-infoを利用したい
  When ユーザーが--format "json"オプションを指定して実行する
  Then モデル情報がJSON形式で出力される
```

**受け入れ基準**:
- [ ] モデル名によるフィルタリング機能
- [ ] 各項目でのソート機能
- [ ] JSON出力形式のサポート
- [ ] カラムの表示/非表示切り替え

**t_wadaスタイル テスト戦略**:
```
E2Eテスト:
- 各フィルタリングオプションのテスト
- ソート機能のテスト
- JSON出力のテスト

統合テスト:
- フィルタリングエンジンと表示機能の連携
- 出力形式の切り替え

単体テスト:
- フィルタリングロジック
- ソートアルゴリズム
- JSONフォーマット処理
```

**見積もり**: 4ストーリーポイント

---

### PBI 5: エラーハンドリングとユーザビリティ向上

**タイトル**: 詳細なエラーメッセージとヘルプ機能

**ユーザーストーリー**:
開発者として、エラーが発生した際に具体的な原因と解決策を知りたい、なぜなら迅速な問題解決が必要だから

**ビジネス価値**:
- ユーザー体験：分かりやすいエラーメッセージ
- 問題解決：自己解決能力の向上
- 学習支援：ツールの効果的な使用方法の提供

**BDD受け入れシナリオ**:
```gherkin
Scenario: ネットワークエラー時に詳細な情報を表示する
  Given ネットワーク接続ができない状態で
  When ユーザーがllm-infoコマンドを実行する
  Then ネットワークエラーであることが明確に表示される
  And 考えられる解決策が提示される

Scenario: ヘルプメッセージを表示する
  When ユーザーがllm-info --helpを実行する
  Then 使用方法とオプション一覧が表示される
  And 実用的な使用例が含まれている
```

**受け入れ基準**:
- [ ] エラー種別ごとの詳細メッセージ
- [ ] 解決策の提示
- [ ] 包括的なヘルプ機能
- [ ] 使用例の提示

**t_wadaスタイル テスト戦略**:
```
単体テスト:
- 各エラーシナリオのメッセージ生成
- ヘルプメッセージのフォーマット
```

**見積もり**: 2ストーリーポイント

---

## 機能拡張版実装計画

### Phase 1: 基本拡張（1週間）
- PBI 1: 標準互換モードと自動フォールバック
- PBI 2: 設定ファイル機能

### Phase 2: 環境対応（1週間）
- PBI 3: 環境変数サポート
- PBI 5: エラーハンドリングとユーザビリティ向上

### Phase 3: 高度な機能（1週間）
- PBI 4: 高度な表示機能

### 合計見積もり: 14ストーリーポイント（3週間）

---

## 技術仕様（機能拡張版）

### 設定ファイル形式
```yaml
gateways:
  - name: "default"
    url: "https://api.example.com"
    api_key: "your-api-key"
  - name: "alternative"
    url: "https://api2.example.com"
    api_key: "another-api-key"
default_gateway: "default"
```

### コマンドラインインターフェース（拡張版）
```bash
# 基本使用
llm-info

# ゲートウェイ指定
llm-info --gateway alternative

# フィルタリングとソート
llm-info --filter "gpt" --sort "max_tokens"

# JSON出力
llm-info --format json

# ヘルプ
llm-info --help
```

### 環境変数
- `LLM_INFO_URL`: ゲートウェイURL
- `LLM_INFO_API_KEY`: APIキー
- `LLM_INFO_DEFAULT_GATEWAY`: デフォルトゲートウェイ名

### 設定の優先順位
1. コマンドライン引数
2. 環境変数
3. 設定ファイル
4. デフォルト値

### 拡張されたプロジェクト構造
```
llm-info/
├── cmd/
│   └── llm-info/
│       └── main.go
├── internal/
│   ├── api/
│   │   ├── client.go
│   │   └── endpoints.go
│   ├── model/
│   │   └── model.go
│   ├── config/
│   │   ├── manager.go
│   │   ├── file.go
│   │   └── env.go
│   ├── ui/
│   │   ├── table.go
│   │   ├── json.go
│   │   └── filter.go
│   └── error/
│       └── handler.go
├── pkg/
│   └── config/
│       └── config.go
├── configs/
│   └── example.yaml
├── go.mod
├── go.sum
└── README.md